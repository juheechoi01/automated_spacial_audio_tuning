{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c86bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "while cv2.waitKey(33) < 0:\n",
    "    ret, frame = capture.read()\n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eff9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "영상에 mediapipe 적용. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53575edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카메라를 찾을 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "#파일 위치 미리 지정\n",
    "input_video_path = \"S#17 촬영본.mp4\"\n",
    "save_video_path = 'S#17 촬영본_output.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "#재생할 파일의 넓이와 높이\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "#video controller\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter(save_video_path, fourcc, 30.0, (int(width), int(height)))\n",
    "\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=1, \n",
    "        min_detection_confidence=0.7) as face_detection:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"카메라를 찾을 수 없습니다.\")\n",
    "            # 웹캠을 불러올 경우는 'continue', 동영상을 불러올 경우 'break'를 사용합니다.\n",
    "            break\n",
    "\n",
    "        # 필요에 따라 성능 향상을 위해 이미지 작성을 불가능함으로 기본 설정합니다.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detection.process(image)\n",
    "\n",
    "        # 포즈 주석을 이미지 위에 그립니다.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                mp_drawing.draw_detection(image, detection)\n",
    "            \n",
    "        # 보기 편하게 이미지를 좌우 반전합니다.\n",
    "        cv2.imshow('MediaPipe Face Detection', image) #코랩에서 돌릴거면 imshow()문은 주석처리할 것.\n",
    "        out.write(image)\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98eeedc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "LOWER_LIP_LEFT",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Face landmark를 가져옵니다.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m landmarks \u001b[38;5;241m=\u001b[39m detection\u001b[38;5;241m.\u001b[39mlocation_data\u001b[38;5;241m.\u001b[39mrelative_keypoints\n\u001b[0;32m---> 38\u001b[0m lip_left_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(landmarks[mp_face\u001b[38;5;241m.\u001b[39mFaceKeyPoint\u001b[38;5;241m.\u001b[39mLOWER_LIP_LEFT]\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m*\u001b[39m iw)\n\u001b[1;32m     39\u001b[0m lip_left_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(landmarks[mp_face\u001b[38;5;241m.\u001b[39mFaceKeyPoint\u001b[38;5;241m.\u001b[39mLOWER_LIP_LEFT]\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m*\u001b[39m ih)\n\u001b[1;32m     41\u001b[0m lip_right_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(landmarks[mp_face\u001b[38;5;241m.\u001b[39mFaceKeyPoint\u001b[38;5;241m.\u001b[39mLOWER_LIP_RIGHT]\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m*\u001b[39m iw)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/enum.py:786\u001b[0m, in \u001b[0;36mEnumType.__getattr__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_member_map_[name]\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 786\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: LOWER_LIP_LEFT"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Mediapipe의 Face 모듈을 사용하기 위한 초기화\n",
    "mp_face = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "face_detection = mp_face.FaceDetection()\n",
    "\n",
    "# 원본 영상 파일 경로\n",
    "video_path = 'S#17 촬영본.mp4'\n",
    "\n",
    "# 원본 영상 파일에서 비디오 캡쳐를 초기화합니다.\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    # 프레임을 읽어옵니다.\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"비디오 읽기 실패\")\n",
    "        break\n",
    "\n",
    "    # BGR을 RGB로 변환합니다.\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Face Detection을 적용합니다.\n",
    "    result = face_detection.process(rgb_frame)\n",
    "\n",
    "    # Face Detection 결과가 있을 경우\n",
    "    if result.detections:\n",
    "        for detection in result.detections:\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            ih, iw, _ = frame.shape\n",
    "            x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "\n",
    "            # Face landmark를 가져옵니다.\n",
    "            landmarks = detection.location_data.relative_keypoints\n",
    "            lip_left_x = int(landmarks[mp_face.FaceKeyPoint.LOWER_LIP_LEFT].x * iw)\n",
    "            lip_left_y = int(landmarks[mp_face.FaceKeyPoint.LOWER_LIP_LEFT].y * ih)\n",
    "\n",
    "            lip_right_x = int(landmarks[mp_face.FaceKeyPoint.LOWER_LIP_RIGHT].x * iw)\n",
    "            lip_right_y = int(landmarks[mp_face.FaceKeyPoint.LOWER_LIP_RIGHT].y * ih)\n",
    "\n",
    "            # 입술 좌표를 출력합니다.\n",
    "            print(\"입술 왼쪽 좌표 (x, y):\", lip_left_x, lip_left_y)\n",
    "            print(\"입술 오른쪽 좌표 (x, y):\", lip_right_x, lip_right_y)\n",
    "\n",
    "            # 입술 좌표를 표시합니다.\n",
    "            cv2.circle(frame, (lip_left_x, lip_left_y), 5, (0, 255, 0), -1)\n",
    "            cv2.circle(frame, (lip_right_x, lip_right_y), 5, (0, 255, 0), -1)\n",
    "\n",
    "    # 화면에 출력합니다.\n",
    "    cv2.imshow('Mediapipe Face', frame)\n",
    "\n",
    "    # 'q' 키를 누르면 종료합니다.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 사용한 자원을 해제합니다.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74403c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in /Users/choejuhui/anaconda3/lib/python3.11/site-packages (0.9.1.0)\n",
      "Requirement already satisfied: absl-py in /Users/choejuhui/anaconda3/lib/python3.11/site-packages (from mediapipe) (2.0.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/choejuhui/anaconda3/lib/python3.11/site-packages (from mediapipe) (22.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/choejuhui/anaconda3/lib/python3.11/site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in /Users/choejuhui/anaconda3/lib/python3.11/site-packages (from mediapipe) (3.7.1)\n",
      "Requirement already satisfied: numpy in /Users/choejuhui/anaconda3/lib/python3.11/site-packages (from mediapipe) (1.24.3)\n",
      "Requirement already satisfied: opencv-contrib-python in /Users/choejuhui/anaconda3/lib/python3.11/site-packages (from mediapipe) (4.8.1.78)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in /Users/choejuhui/anaconda3/lib/python3.11/site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/choejuhui/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/choejuhui/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/choejuhui/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/choejuhui/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/choejuhui/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/choejuhui/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/choejuhui/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/choejuhui/anaconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/choejuhui/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mediapipe --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dffed69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 11:40:10.642407: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Mediapipe Face Mesh 초기화\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh()\n",
    "\n",
    "# 동영상 파일 경로\n",
    "video_path = 'S#17 촬영본.mp4'  # 동영상 파일 경로를 적절히 수정하세요.\n",
    "\n",
    "# OpenCV 초기화\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # BGR 이미지를 RGB로 변환\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Face Mesh를 이용하여 얼굴 landmark 검출\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    # 얼굴 landmark가 검출되었다면\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # 입술 좌표 얻기\n",
    "            for idx, landmark in enumerate(face_landmarks.landmark):\n",
    "                height, width, _ = frame.shape\n",
    "                cx, cy = int(landmark.x * width), int(landmark.y * height)\n",
    "\n",
    "                # 입술 부분만 출력\n",
    "                if 48 <= idx <= 59:\n",
    "                    cv2.circle(frame, (cx, cy), 2, (0, 255, 0), -1)\n",
    "\n",
    "    # 결과를 화면에 출력\n",
    "    cv2.imshow('Face Mesh', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # 'Esc' 키를 누르면 종료\n",
    "        break\n",
    "\n",
    "# 정리 작업\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b874e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
